{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d926cfb",
   "metadata": {},
   "source": [
    "# 1.Project Overview & Data Acquisition\n",
    "\n",
    "## 1.1 Introduction\n",
    "\n",
    "This project utilizes raw data sourced from the public Australian websites of three major supermarket chains: Woolworths, Aldi, and Coles. The datasets primarily include essential product attributes such as **SKU name, category, and price information**.\n",
    "\n",
    "## 1.2 Data Acquisition Method\n",
    "\n",
    "Product information was extracted from publicly accessible web pages using an automated Python script, thereby establishing a pricing monitoring dataset.\n",
    "\n",
    "## 1.3 Compliance and Usage Declaration\n",
    "\n",
    "**This project strictly adheres to ethical data collection standards.**\n",
    "\n",
    "* All data was collected exclusively from publicly accessible webpages.\n",
    "* The collection process did not involve logging in, bypassing access restrictions, or accessing non-public data.\n",
    "* The datasets are used solely for the purpose of **technical learning and skill development**, and do not involve commercial use or large-scale redistribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638d463",
   "metadata": {},
   "source": [
    "# 2. Raw Data Description & Schema\n",
    "\n",
    "The following table summarizes the key characteristics of the raw data collected from the three supermarket websites.\n",
    "\n",
    "| Supermarket | Acquisition Date | Table Name | Rows | Columns |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| Woolworths | 2025-11-11 | wws_drinks | 2687 | 11 |\n",
    "| Aldi | 2025-11-11 | aldi_drinks | 177 | 7 |\n",
    "| Coles | 2025-11-10 | coles_drinks | 1485 | 8 |\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Column Definitions\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| **name** | Display name of the beverage product. |\n",
    "| **brand** | Brand name of the beverage. |\n",
    "| **instore_price** | Current in-store price (Lower than `instore_was_price` if on promotion). |\n",
    "| **instore_was_price** | Original in-store price. |\n",
    "| **instore_cup_price** | In-store price per `cup_measure` unit. |\n",
    "| **online_price** | Current online price. |\n",
    "| **online_was_price** | Original online price. |\n",
    "| **online_cup_price** | Online price per `cup_measure` unit. |\n",
    "| **package_size** | Packaging volume/capacity of the product. |\n",
    "| **save_percent** | Discount percentage. |\n",
    "| **category** | Product classification. |\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Data Collection Nuances & Missingness Notes\n",
    "\n",
    "**Important Context for Data Missingness:**\n",
    "\n",
    "* **Aldi:** The official Aldi website only displays products and does not operate an online store. Consequently, the Aldi dataset contains **only in-store pricing data** and has no online price columns.\n",
    "* **Coles:** The Coles online page exclusively displays online pricing. As a result, the Coles dataset has **no in-store pricing data** (e.g., `instore_price`, `instore_was_price`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce404786",
   "metadata": {},
   "source": [
    "# 3.Data Cleaning\n",
    "\n",
    "## 3.1 Initial Data Cleaning and Pre-Processing (Excel Operations)\n",
    "\n",
    "The first phase of data cleaning was conducted using Microsoft Excel's functionalities for quick structural adjustments, noise removal, and initial missing value imputation.\n",
    "\n",
    "### 3.1.1 Duplicate Removal\n",
    "\n",
    "Duplicates were removed across all three datasets to ensure unique records.\n",
    "\n",
    "| Table Name | Rows Removed | Remaining Rows | Tool Used |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `wws_drinks` | 790 | 1896 | Excel (Remove Duplicates) |\n",
    "| `aldi_drinks` | 0 | 177 | Excel (Remove Duplicates) |\n",
    "| `coles_drinks` | 1 | 1484 | Excel (Remove Duplicates) |\n",
    "\n",
    "### 3.1.2 Non-Core Product and Outlier Removal\n",
    "\n",
    "Non-beverage products, promotional hampers, and extreme outliers were identified and removed.\n",
    "\n",
    "#### Woolworths (`wws_drinks`)\n",
    "\n",
    "* **Handling Logic:** Filters were applied to the `category` column to identify and remove gift/hampers.\n",
    "* **Categories Removed:**\n",
    "    * `[\"Hampers & Gifting\", \"Pantry\"]`: 16 rows\n",
    "    * `[\"Gifts, Wrapping & Cards\", \"Hampers & Gifting\", \"Pantry\"]`: 14 rows\n",
    "* **Result:** **30 rows** of noise data were removed. Remaining rows: 1866.\n",
    "\n",
    "#### Aldi (`aldi_drinks`)\n",
    "\n",
    "* **Handling Logic:** Data was sorted by price descendingly. An outlier was identified as a non-beverage machine.\n",
    "* **Outlier Removed:** 1 row (Product: \"Coffee Capsule Machine,\" Price: 78.99).\n",
    "* **Result:** Remaining rows: 176.\n",
    "\n",
    "#### Coles (`coles_drinks`)\n",
    "\n",
    "* **Assessment:** No obvious noise data or outliers were detected.\n",
    "\n",
    "### 3.1.3 Missing Value Imputation \n",
    "\n",
    "Initial filling of missing price data based on assumed promotional logic.\n",
    "\n",
    "#### Woolworths (`wws_drinks`)\n",
    "\n",
    "| Modification | Original State | Imputation Logic | Imputation Method | Rows Modified |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Online Price** | `online_price` is missing | If `online_price` is missing, assume it equals the original price. | `online_price = online_was_price` | 54 |\n",
    "| **In-store Price** | `instore_price` is missing | If `instore_price` is missing, assume it equals the original price. | `instore_price = instore_was_price` | 54 |\n",
    "\n",
    "#### Coles (`coles_drinks`)\n",
    "\n",
    "| Modification | Target Object | Imputation Logic | Imputation Method | Rows Modified |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Modification 1** | `online_was_price` = 0 (Missing) | Products without an original price are assumed to be non-discounted. | `online_was_price = online_price` | 1060 |\n",
    "| **Modification 2** | `save_percent` is blank AND `online_was_price` = 0 | Products with no original price and no save percent are not discounted. | `save_percent = 0` | 1060 |\n",
    "| **Modification 3** | `save_percent` is blank AND `online_was_price` $\\ne$ 0 | Calculate the discount percentage using known price data. | `save_percent = (online\\_was\\_price - online\\_price) / online\\_was\\_price * 100` | 494 |\n",
    "\n",
    "### 3.1.4 Data Standardization (Unit & Format)\n",
    "\n",
    "#### Aldi (`aldi_drinks`)\n",
    "\n",
    "* **Modification:** `instore_price`, `instore_was_price`.\n",
    "* **Logic:** Original data was recorded in **cents**.\n",
    "* **Method:** Multiply the entire column by $\\mathbf{0.01}$ to convert to dollars.\n",
    "* **Rows Modified:** 177\n",
    "\n",
    "#### Coles (`coles_drinks`)\n",
    "\n",
    "* **Modification:** `save_percent`.\n",
    "* **Logic:** Convert the value to a percentage format and limit to 2 decimal places.\n",
    "* **Method:** Multiply the entire column by $\\mathbf{0.01}$ and apply percentage formatting.\n",
    "* **Rows Modified:** 1484\n",
    "\n",
    "## 3.2 Schema Standardization and Data Unification (Pandas)\n",
    "\n",
    "This phase transitions the data processing to Python/Pandas to efficiently handle schema inconsistencies, column standardization, and the final data union.\n",
    "\n",
    "### 3.2.1 Schema Standardization and Column Alignment\n",
    "\n",
    "The three retail datasets (`wws_drinks`, `aldi_drinks`, `coles_drinks`) have differing column structures due to varying data availability from their respective websites. The goal of this step is to enforce a uniform schema across all tables prior to unification.\n",
    "\n",
    "#### **Canonical Column List (`CANON_COLS`)**\n",
    "CANON_COLS = [\n",
    "    \"retailer\", \"name\", \"brand\", \"package_size\",\n",
    "    \"instore_price\", \"instore_was_price\",\n",
    "    \"online_price\", \"online_was_price\", \"save_percent\",\n",
    "    \"category_original\", \"category_std\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ccd11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "XSLX = \"drinks.xlsx\"\n",
    "xls = pd.ExcelFile(XSLX)\n",
    "\n",
    "sheets = pd.read_excel(XSLX, sheet_name=None, dtype=str, keep_default_na=False)\n",
    "retailer_map = {\n",
    "    \"Woolworth\" : \"wws_drinks\",\n",
    "    \"Aldi\" : \"aldi_drinks\",\n",
    "    \"Coles\" : \"coles_drinks\"\n",
    "}\n",
    "CANON_COLS = [\n",
    "    \"retailer\", \"name\", \"brand\", \"package_size\",\n",
    "    \"instore_price\",\"instore_was_price\",\n",
    "    \"online_price\", \"online_was_price\", \"save_percent\",\n",
    "    \"category_original\", \"category_std\"\n",
    "]\n",
    "\n",
    "def check_cols(df:pd.DataFrame, cols):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df\n",
    "\n",
    "def standardize(df_raw:pd.DataFrame, retailer:str):\n",
    "    df = df_raw.copy()\n",
    "    df[\"retailer\"] = retailer\n",
    "    df[\"category_original\"] = df[\"category\"]\n",
    "    df = check_cols(df, CANON_COLS)\n",
    "    df = df[CANON_COLS]\n",
    "    return df\n",
    "\n",
    "std_dfs = {}\n",
    "for (retailer,sheet_name) in retailer_map.items():\n",
    "    df_raw = sheets[sheet_name]\n",
    "    df_std = standardize(df_raw, retailer)\n",
    "    std_dfs[retailer] = df_std\n",
    "\n",
    "\n",
    "out_dir = Path(\"intermediate\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "for retailer, df in std_dfs.items():\n",
    "    df.to_csv(out_dir / f\"{retailer.lower()}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22f4b2",
   "metadata": {},
   "source": [
    "#### Result\n",
    "Three standardized intermediate datasets were saved: 'woolworth.csv', 'coles.csv','aldi.csv'\n",
    "Each possessing an identical column structure and order,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804054bf",
   "metadata": {},
   "source": [
    "### 3.2 Category Unification and Standardization (`category_std`)\n",
    "\n",
    "The raw data presents a major challenge due to the lack of a consistent classification system across the three retailers, leading to high category complexity and inconsistency.\n",
    "\n",
    "#### **Standardized Category List**\n",
    "\n",
    "To enable comparative analysis, all products were mapped to the following eight unified categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7816f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\n",
    "    \"Non/Low Alcoholic\",\n",
    "    \"Water\",\n",
    "    \"Milk\",\n",
    "    \"Coffee\",\n",
    "    \"Soft Drink\",\n",
    "    \"Sport & Energy\",\n",
    "    \"Tea & Juice\",\n",
    "    \"Other drinks\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef69dd4e",
   "metadata": {},
   "source": [
    "#### **Category Standardization Logic: Two-Pass Regular Expression Approach**\n",
    "\n",
    "Due to the extreme ambiguity and complex keyword concatenation used in the original `category` columns (e.g., Woolworths and Coles often combine keywords like `Tea & [Coffee,\"Everyday Market\",\"Coffee\"]` or `[ENERGY/SPORT/ICEDTEA]`), direct mapping from the original category column was impractical.\n",
    "\n",
    "The standardization was performed in a **two-pass iterative process** primarily relying on the **product name** (`name`) column.\n",
    "\n",
    "##### **Pass 1: Name-Based Regular Expression Mapping**\n",
    "\n",
    "* **Logic:** Products were initially classified by applying comprehensive regular expressions (`pat` variables) against the product **`name`** field.\n",
    "* **Goal:** To capture the vast majority of clearly identifiable products (e.g., \"Coca Cola\" for \"Soft Drink\").\n",
    "* **Result:** Ambiguously named products (e.g., \"Variety Pack 30 Pack 375ml\" or \"Original Lemon 600ml\") that could not be determined solely from the name were temporarily classified into **\"Other drinks\"**.\n",
    "\n",
    "##### **Pass 2: Re-classification of \"Other drinks\" using Original Category**\n",
    "\n",
    "* **Problem:** After Pass 1, a significant number of products remained in the \"Other drinks\" bucket (e.g., 340 items in Woolworths initially).\n",
    "* **Logic:** The `category_original` column was then used as a secondary source. A simpler regular expression pass was executed *only* on the products classified as \"Other drinks\" to utilize keywords from the original, retailer-specific category data.\n",
    "* **Result:** This secondary pass successfully re-classified approximately **90%** of the remaining \"Other drinks\" items. (Example: Woolworths' \"Other drinks\" count dropped to 11 items after this pass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea985d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Woolworth:\n",
      "Tea & Juice          742\n",
      "Coffee               391\n",
      "Soft Drink           295\n",
      "Sport & Energy       158\n",
      "Milk                 156\n",
      "Water                 70\n",
      "Non/Low Alcoholic     43\n",
      "Other drinks          11\n",
      "Name: category_std, dtype: int64\n",
      "\n",
      "Aldi:\n",
      "Tea & Juice       63\n",
      "Coffee            51\n",
      "Soft Drink        34\n",
      "Water             11\n",
      "Milk               9\n",
      "Sport & Energy     8\n",
      "Name: category_std, dtype: int64\n",
      "\n",
      "Coles:\n",
      "Tea & Juice          594\n",
      "Coffee               337\n",
      "Soft Drink           238\n",
      "Milk                 126\n",
      "Sport & Energy       118\n",
      "Water                 55\n",
      "Non/Low Alcoholic     15\n",
      "Other drinks           1\n",
      "Name: category_std, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning \n",
    "\n",
    "warnings.filterwarnings(\n",
    "    'ignore', \n",
    "    message=\"This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\",\n",
    "    category=UserWarning\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning) \n",
    "\n",
    "\n",
    "FLAVORS = r\"(apple|orange|mango|pineapple|lychee|peach|pear|grape|grapefruit|berry|strawberry|blueberry|raspberry|blackberry|cranberry|lemon|lime|passion(?:fruit)?|guava|pomegranate|watermelon|melon|kiwi|apricot|cherry|yuzu)\"\n",
    "# the order is seted by the consideration of:\n",
    "# ginger beer (belong to soft drink instead of non Alcoholic)\n",
    "# tonic water (soft drink / not water)\n",
    "# Gatorade G Active Sports Drinks Berry Water Electrolytes ï¼ˆsport & energy/ not water)\n",
    "# so, soft drink/sport & energy > water/ alcoholic\n",
    "name_patterns = {\n",
    "    \"Milk\": r\"\\b(milk|oat\\s+milk|almond\\s+milk|dairy)\\b\",\n",
    "    \"Sport & Energy\": r\"\\b(sports?|electrolytes?|energy|enery|protein)\\b\",\n",
    "    \"Soft Drink\": rf\"(?:\\b(?:tonic|ginger\\s+(?:ale|beer)|cola|soft drink|lemonade|pepsi|sunkist|passiona|cream\\s+soda)\\b|(?:\\b{FLAVORS}\\b[\\s-]*soda(?!\\s*water)|\\bsoda\\b(?!\\s*water)[\\s-]*\\b{FLAVORS}\\b))\",\n",
    "    \"Non/Low Alcoholic\": r\"\\b(beer|vodka|alcohol|heineken|non[-\\s]?alc|alcohol[-\\s]?free)\\b\",\n",
    "    \"Coffee\": r\"\\b(coffe(e)|iced\\s*coffee|latte|cappuccino|mocha|espresso|americano)\\b\",\n",
    "    \"Tea & Juice\": rf\"\\b(?:(?:juice|nectar|fruit\\s*drink|cordial|syrup|concentrate)|(?:tea|herbal|iced\\s*tea|green\\s*tea|black\\s*tea|matcha|earl\\s*grey|oolong|chai|k[ou]mbu?cha)|(?:.*?\\b{FLAVORS}\\b.*))\\b\",\n",
    "    \"Water\": r\"\\b(water)\\b\"\n",
    "}\n",
    "\n",
    "category_patterns = {\n",
    "    \"Milk\": r\"\\b(milk|oat\\s+milk|almond\\s+milk|dairy)\\b\",\n",
    "    \"Sport & Energy\": r\"\\b(sports drinks|electrolytes?|energy|protein)\\b\",\n",
    "    \"Soft Drink\": r\"(soft\\s?drinks?|cold\\s?drink)\",\n",
    "    \"Tea & Juice\" : r\"(juice|Cordials|tea)\",\n",
    "    \"Coffee\" : r\"coffee\",\n",
    "    \"Non/Low Alcoholic\": r\"\\b(beer|alcohol|wine|non[-\\s]?alc|alcoholic)\\b\",\n",
    "    \"Water\" : r\"water\",\n",
    "}\n",
    "def standardize_category(df: pd.DataFrame):\n",
    "    out = df.copy()\n",
    "    out[\"category_std\"] = out[\"category_std\"].fillna(\"Unmapped\")\n",
    "\n",
    "    base = out[\"category_std\"].eq(\"Unmapped\")\n",
    "    # Firstly Use 'name' to decide category\n",
    "    for cat, pat in name_patterns.items():\n",
    "        m = base & out[\"name\"].str.contains(pat, case=False, na=False, regex=True)\n",
    "        out.loc[m, \"category_std\"] = cat\n",
    "        base = out[\"category_std\"].eq(\"Unmapped\")\n",
    "\n",
    "    # Use \"category_original\" decide if unmapped after name_patterns.\n",
    "    for cat, pat in category_patterns.items():\n",
    "        m = base & out[\"category_original\"].str.contains(pat, case=False, na=False, regex=True)\n",
    "        out.loc[m, \"category_std\"] = cat\n",
    "        base = out[\"category_std\"].eq(\"Unmapped\")\n",
    "\n",
    "    out.loc[out[\"category_std\"].eq(\"Unmapped\"), \"category_std\"] = \"Other drinks\"\n",
    "    return out\n",
    "\n",
    "inter_dir = Path(\"intermediate\")\n",
    "in_files = {\n",
    "    \"Woolworth\": inter_dir / \"woolworth.csv\",\n",
    "    \"Aldi\":      inter_dir / \"aldi.csv\",\n",
    "    \"Coles\":     inter_dir / \"coles.csv\",\n",
    "}\n",
    "\n",
    "for retailer, path in in_files.items():\n",
    "    df = pd.read_csv(path, dtype=str, keep_default_na=True)\n",
    "    df2 = standardize_category(df)\n",
    "    df2.to_csv(path, index=False)\n",
    "    \n",
    "    print(f\"\\n{retailer}:\")\n",
    "    print(df2[\"category_std\"].value_counts(dropna=False))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd0108",
   "metadata": {},
   "source": [
    "#### **Final Outcome**\n",
    "\n",
    "* **Final `Other drinks`:** This category now serves as the final **catch-all bucket** for truly ambiguous or unique products that cannot be reliably classified (e.g., \"Remedy Shots Digestion 12 x 60ml\").\n",
    "* **Conclusion:** Following this two-pass iterative adjustment, the category schemas of all three retailers were unified, and the classification accuracy was judged to be near-precise after manual verification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edb8c9",
   "metadata": {},
   "source": [
    "### 3.3 Price Granularity Alignment and Imputation \n",
    "This step focuses on addressing the retailer-specific gaps in pricing columns (`save_percent`, `instore_price`, `instore_was_price`) to ensure a consistent data granularity across the three finalized tables before the final union.\n",
    "\n",
    "#### Woolworths: Imputing Missing Discount Depth (`save_percent`)\n",
    "\n",
    "Woolworths data lacked a pre-calculated `save_percent` column. This was calculated using the available *in-store* price fields.\n",
    "\n",
    "* **Logic:** For records where `save_percent` was missing (`NaN`), the value was calculated using the formula: $$\\text{Save Percent} = \\frac{(\\text{instore_was_price} - \\text{instore_price})}{\\text{instore_was_price}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7b3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inter_dir = Path('intermediate')\n",
    "wws = inter_dir/\"woolworth.csv\"\n",
    "df_wws = pd.read_csv(wws)\n",
    "\n",
    "df_wws['instore_was_price'] = pd.to_numeric(df_wws['instore_was_price'])\n",
    "df_wws['instore_price'] = pd.to_numeric(df_wws['instore_price'])\n",
    "\n",
    "save_percent = (df_wws['instore_was_price'] - df_wws['instore_price']) / df_wws['instore_was_price']\n",
    "df_wws['save_percent'] = df_wws['save_percent'].fillna(save_percent)\n",
    "\n",
    "df_wws.to_csv(wws, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38b5a2",
   "metadata": {},
   "source": [
    "#### Aldi: Imputing Missing Discount Depth (`save_percent`)\n",
    "Same as Woolworth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13e785f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aldi = inter_dir/\"aldi.csv\"\n",
    "df_aldi = pd.read_csv(aldi)\n",
    "\n",
    "df_aldi['instore_was_price'] = pd.to_numeric(df_aldi['instore_was_price'])\n",
    "df_aldi['instore_price'] = pd.to_numeric(df_aldi['instore_price'])\n",
    "\n",
    "save_percent = (df_aldi['instore_was_price'] - df_aldi['instore_price']) / df_aldi['instore_was_price']\n",
    "df_aldi['save_percent'] = df_aldi['save_percent'].fillna(save_percent)\n",
    "\n",
    "df_aldi.to_csv(aldi, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a5518",
   "metadata": {},
   "source": [
    "#### Coles: Aligning Online and In-store Prices\n",
    "Coles data only provides online pricing. To align the data with the other retailers, Coles' online prices were explicitly copied to the in-store price fields to fill the missing instore columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a5d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "coles = inter_dir/'coles.csv'\n",
    "df_coles = pd.read_csv(coles)\n",
    "\n",
    "df_coles['instore_price'] = df_coles['instore_price'].fillna(df_coles['online_price'])\n",
    "df_coles['instore_was_price'] = df_coles['instore_was_price'].fillna(df_coles['online_was_price'])\n",
    "\n",
    "df_coles.to_csv(coles, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56008e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
